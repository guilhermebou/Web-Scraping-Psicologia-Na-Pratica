# ğŸ“Œ Estudo de Viabilidade | Web Scraping do Site Psicologia Na PrÃ¡tica

Este projeto realiza a coleta automatizada de informaÃ§Ãµes do site [Psicologia Na PrÃ¡tica](https://www.psicologianapratica.com/material-gratuito). As informaÃ§Ãµes extraÃ­das incluem o tÃ­tulo do material, descriÃ§Ã£o, imagem e link para download.

## **ğŸ·ï¸ Nota** 
Nesta implementacao utilizamos o python em sua versao 3.10.4, a biblioteca python BeautifulSoup em sua versÃ£o 4.12.2 ela Ã© utilizada para realizar a raspagem de dados (web scraping), biblioteca python NLTK na versÃ£o 3.8.1 para o processo do prÃ©-processamento com a tokenizaÃ§Ã£o, utilizado o dicionario [LIWC Portugues](http://143.107.183.175:21380/portlex/index.php/pt/projetos/liwc), tambÃ©m utilizado a Interface de ProgramaÃ§Ã£o de AplicaÃ§Ã£o (API) GPT-3.5-Turbo para realizar a analise, identificaÃ§Ã£o e listagem das expressÃµes desejadas, por ultimo, utilizado a biblioteca Requests 2.31.0 para realizar a requisiÃ§ao nos sites obtendo o "Hypertext Transfer Protocol" (HTTP). O desenvolvimento foi realizado em uma mÃ¡quina com sistema operacional de 64 bit- Windows 10 Home.

## **ğŸ“ Requisitos/InstalaÃ§Ã£o âš™ï¸** 

â–¶ï¸ **Python 3.10.4:** Download no site oficial do Python
(https://www.python.org).

â–¶ï¸ **Biblioteca Beautiful Soup 4.12.2:** Utilizada para extrair e manipular dados de arquivos HTML e XML. [DocumentaÃ§Ã£o do BeautifulSoup](https://pypi.org/project/beautifulsoup4/).

Para a instalaÃ§Ã£o da biblioteca Ã© necessÃ¡rio utilizar o gerenciador de pacotes 'pip'. Abra o terminal ou prompt de comando e execute o seguinte comando: 
```terminal
pip install beautifulsoup4==4.12.2
```

â–¶ï¸ **Biblioteca Requests 2.31.0:** Usada para fazer requisiÃ§Ãµes HTTP. [DocumentaÃ§Ã£o do requests](https://docs.python-requests.org/) 
    Para a instalaÃ§Ã£o da biblioteca Ã© necessÃ¡rio utilizar o gerenciador de pacotes 'pip'. Abra o terminal ou prompt de comando e execute o seguinte comando: 
```terminal
pip install requests==2.31.0
```
â–¶ï¸ **Biblioteca Pandas 2.1.2:** Para manipulaÃ§Ã£o e anÃ¡lise de dados em formato tabular. [DocumentaÃ§Ã£o do Pandas](https://pandas.pydata.org/)
    Para a instalaÃ§Ã£o da biblioteca Ã© necessÃ¡rio utilizar o gerenciador de pacotes 'pip'. Abra o terminal ou prompt de comando e execute o seguinte comando: 
```terminal
pip install pandas==2.1.2
```

## ğŸ”§ğŸ² Processo de ExtraÃ§Ã£o de Dados

O processo de extraÃ§Ã£o de dados segue os passos descritos abaixo:

1. ğŸ”— Definir a URL da pÃ¡gina a ser acessada:
   ```python
   url = "https://www.psicologianapratica.com/material-gratuito"
   ```
2. ğŸ“¨ Fazer uma requisiÃ§Ã£o HTTP GET para a URL definida:
  ```python
      request = requests.get(url)
  ```
3. ğŸ“¦ Converter o conteÃºdo da resposta em um objeto BeautifulSoup para facilitar a busca por elementos HTML:
   ```python
   soup = BeautifulSoup(request.content, 'html.parser')
   ```
   
4. ğŸ” Buscar os elementos da pÃ¡gina correspondentes ao tÃ­tulo, descriÃ§Ã£o, links e imagens:
   ```python
   titulo = soup.find_all('h3', class_='h4 card-title text-center border-bottom pb-1 mb-2')
    descricao = soup.find_all('p', class_='card-text text-center')
    link_download = soup.find_all('a', class_='mt-2 btn w-100 fw-bold')
    imagem = soup.find_all('img', class_='card-img-top img-thumbnail w-100')
    ```
5. ğŸ”  Extrair os textos dos tÃ­tulos e descriÃ§Ãµes, criando listas com os dados:
   ```python
   titulos = [i.text.strip().replace('\n', '').replace('\r', '').strip() for i in titulo]
    descricoes = [desc.text.strip().replace('\n', '').replace('\r', '').strip() for desc in descricao]
    ```
6. ğŸ”— Criar a URL completa dos links de download:
   ```python
   links = [url + link.get('href') for link in link_download]
    ```
7. ğŸ–¼ï¸ Extrair o link das imagens:
   ```python
   imgs = [img.get('src') for img in imagem]
    ```
   
## ğŸ²ğŸ“… Armazenamento dos Dados 
   
8. ğŸ“„ Criar um DataFrame usando pandas com os dados extraÃ­dos:
     ```python
   df = pd.DataFrame({
    'titulo': titulos,
    'descricao': descricoes,
    'link': links,
    'img': imgs
    })
    ```
9. ğŸ—‚ï¸ Exportar o DataFrame para um arquivo CSV:
    ```python
   df.to_csv('docs/scrapingconteudosgratuitos.csv', index=False)
    ```
